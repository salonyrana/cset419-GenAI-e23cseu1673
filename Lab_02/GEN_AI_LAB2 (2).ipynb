{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "Z_b3FX4mqkLh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== USER INPUTS =====\n",
        "dataset_choice = \"mnist\"   # \"mnist\" or \"fashion\"\n",
        "epochs = 30\n",
        "batch_size = 64\n",
        "noise_dim = 100\n",
        "learning_rate = 0.0002\n",
        "save_interval = 5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "gmYbKTDhqnwq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "if dataset_choice == \"mnist\":\n",
        "    dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "elif dataset_choice == \"fashion\":\n",
        "    dataset = datasets.FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "else:\n",
        "    raise ValueError(\"Invalid dataset choice\")\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYmlQC3Uqu5Q",
        "outputId": "01be0bfe-0ba5-4144-cf21-ce31ba837e59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 508kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.70MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 13.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img.view(-1, 1, 28, 28)\n",
        "\n",
        "generator = Generator().to(device)\n"
      ],
      "metadata": {
        "id": "5So5oyLgq1lI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        return self.model(img_flat)\n",
        "\n",
        "discriminator = Discriminator().to(device)\n"
      ],
      "metadata": {
        "id": "40pH_yXOq43D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "xMHhwoK_q8LT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"generated_samples\", exist_ok=True)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for real_imgs, _ in dataloader:\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        batch_size_curr = real_imgs.size(0)\n",
        "\n",
        "        real_labels = torch.ones(batch_size_curr, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size_curr, 1).to(device)\n",
        "\n",
        "        # ----- Train Discriminator -----\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        real_preds = discriminator(real_imgs)\n",
        "        d_real_loss = criterion(real_preds, real_labels)\n",
        "\n",
        "        noise = torch.randn(batch_size_curr, noise_dim).to(device)\n",
        "        fake_imgs = generator(noise)\n",
        "        fake_preds = discriminator(fake_imgs.detach())\n",
        "        d_fake_loss = criterion(fake_preds, fake_labels)\n",
        "\n",
        "        d_loss = d_real_loss + d_fake_loss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        d_acc = ((real_preds > 0.5).float().mean() +\n",
        "                 (fake_preds < 0.5).float().mean()) / 2 * 100\n",
        "\n",
        "        # ----- Train Generator -----\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        fake_preds = discriminator(fake_imgs)\n",
        "        g_loss = criterion(fake_preds, real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs} | D_loss: {d_loss.item():.2f} | D_acc: {d_acc:.2f}% | G_loss: {g_loss.item():.2f}\")\n",
        "\n",
        "    if epoch % save_interval == 0:\n",
        "        save_image(fake_imgs[:25], f\"generated_samples/epoch_{epoch:02d}.png\", nrow=5, normalize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHCJaKeSq_o9",
        "outputId": "f8dff85e-5bc8-4a6d-82c4-2a42797d24fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 | D_loss: 0.14 | D_acc: 98.44% | G_loss: 3.19\n",
            "Epoch 2/30 | D_loss: 1.65 | D_acc: 59.38% | G_loss: 2.24\n",
            "Epoch 3/30 | D_loss: 1.02 | D_acc: 82.81% | G_loss: 2.41\n",
            "Epoch 4/30 | D_loss: 0.18 | D_acc: 96.88% | G_loss: 3.19\n",
            "Epoch 5/30 | D_loss: 0.66 | D_acc: 90.62% | G_loss: 2.31\n",
            "Epoch 6/30 | D_loss: 0.47 | D_acc: 93.75% | G_loss: 4.20\n",
            "Epoch 7/30 | D_loss: 0.53 | D_acc: 89.06% | G_loss: 1.86\n",
            "Epoch 8/30 | D_loss: 0.58 | D_acc: 85.94% | G_loss: 2.33\n",
            "Epoch 9/30 | D_loss: 0.69 | D_acc: 82.81% | G_loss: 2.70\n",
            "Epoch 10/30 | D_loss: 0.49 | D_acc: 92.19% | G_loss: 2.94\n",
            "Epoch 11/30 | D_loss: 0.35 | D_acc: 92.19% | G_loss: 2.64\n",
            "Epoch 12/30 | D_loss: 0.55 | D_acc: 90.62% | G_loss: 2.41\n",
            "Epoch 13/30 | D_loss: 0.63 | D_acc: 89.06% | G_loss: 3.87\n",
            "Epoch 14/30 | D_loss: 0.68 | D_acc: 84.38% | G_loss: 2.59\n",
            "Epoch 15/30 | D_loss: 0.47 | D_acc: 85.94% | G_loss: 2.81\n",
            "Epoch 16/30 | D_loss: 0.72 | D_acc: 81.25% | G_loss: 1.64\n",
            "Epoch 17/30 | D_loss: 0.89 | D_acc: 82.81% | G_loss: 2.47\n",
            "Epoch 18/30 | D_loss: 0.71 | D_acc: 82.81% | G_loss: 2.63\n",
            "Epoch 19/30 | D_loss: 0.95 | D_acc: 84.38% | G_loss: 2.33\n",
            "Epoch 20/30 | D_loss: 0.88 | D_acc: 78.12% | G_loss: 1.52\n",
            "Epoch 21/30 | D_loss: 0.75 | D_acc: 82.81% | G_loss: 2.35\n",
            "Epoch 22/30 | D_loss: 1.01 | D_acc: 75.00% | G_loss: 1.54\n",
            "Epoch 23/30 | D_loss: 0.90 | D_acc: 81.25% | G_loss: 1.92\n",
            "Epoch 24/30 | D_loss: 0.74 | D_acc: 84.38% | G_loss: 1.91\n",
            "Epoch 25/30 | D_loss: 0.84 | D_acc: 79.69% | G_loss: 1.82\n",
            "Epoch 26/30 | D_loss: 1.31 | D_acc: 67.19% | G_loss: 2.10\n",
            "Epoch 27/30 | D_loss: 0.69 | D_acc: 84.38% | G_loss: 2.20\n",
            "Epoch 28/30 | D_loss: 0.89 | D_acc: 78.12% | G_loss: 1.48\n",
            "Epoch 29/30 | D_loss: 0.53 | D_acc: 87.50% | G_loss: 2.07\n",
            "Epoch 30/30 | D_loss: 0.83 | D_acc: 76.56% | G_loss: 1.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"final_generated_images\", exist_ok=True)\n",
        "\n",
        "noise = torch.randn(100, noise_dim).to(device)\n",
        "final_images = generator(noise).detach().cpu()\n",
        "\n",
        "for i, img in enumerate(final_images):\n",
        "    save_image(img, f\"final_generated_images/img_{i}.png\", normalize=True)\n",
        "\n",
        "print(\"✅ 100 final images generated\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxRbIyGss6Yr",
        "outputId": "0ddeec94-3cc7-4371-8c08-bfdcc74b8493"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 100 final images generated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "classifier = models.resnet18(pretrained=True)\n",
        "classifier.eval()\n",
        "\n",
        "labels = []\n",
        "\n",
        "for img in final_images:\n",
        "    img = img.repeat(3,1,1).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = classifier(img)\n",
        "        labels.append(output.argmax().item())\n",
        "\n",
        "counts = Counter(labels)\n",
        "\n",
        "print(\"\\n--- Label Distribution ---\")\n",
        "for label, count in sorted(counts.items()):\n",
        "    print(f\"Label {label}: {count} images\")\n"
      ],
      "metadata": {
        "id": "r00j3DPTtBhd",
        "outputId": "e9e608a1-265d-4f55-b63e-938e0e4173f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 195MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Label Distribution ---\n",
            "Label 49: 1 images\n",
            "Label 58: 1 images\n",
            "Label 111: 1 images\n",
            "Label 327: 3 images\n",
            "Label 403: 5 images\n",
            "Label 458: 48 images\n",
            "Label 500: 3 images\n",
            "Label 510: 2 images\n",
            "Label 528: 1 images\n",
            "Label 685: 4 images\n",
            "Label 761: 1 images\n",
            "Label 772: 4 images\n",
            "Label 815: 12 images\n",
            "Label 847: 1 images\n",
            "Label 878: 7 images\n",
            "Label 913: 1 images\n",
            "Label 922: 2 images\n",
            "Label 971: 3 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFtSxj7VtFzH"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}